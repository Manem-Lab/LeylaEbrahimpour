{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b245837e-cf6a-4b3b-9973-fdea326f1679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neuroCombat as nC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ranksums, ttest_ind, ttest_rel, ks_2samp\n",
    "import os\n",
    "import Nestedcombat as nested\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#import GMMComBat as gmmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65787c62-3774-44ee-820a-c732f6759664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset with radiomic features :  (95, 1238)\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "main_dir= \"/home/ulaval.ca/lesee/projects/Project-CNET/\"\n",
    "\n",
    "#data = pd.read_excel(os.path.join(main_dir,'data/LORD-CNET-rads-clinical-combat.xlsx'))\n",
    "data = pd.read_csv(os.path.join(main_dir,'data/radiomics_CNET_updated_bin_0_05_batch_clinical.csv'))\n",
    "#print(data)\n",
    "\n",
    "# Filter the data for stage\n",
    "#filtered_data = data[data['Stage'].isin([1,2])]\n",
    "\n",
    "# Explicitly create a copy of the data\n",
    "filtered_data_copy = data.copy()\n",
    "\n",
    "#drop columns not used in this work\n",
    "filtered_data_copy.drop(columns = ['Center', 'pixel_spacing', 'StudyInstanceUID', 'Recurrence', 'OS_days', 'PFS_days', 'manufacturer', 'Subtype'], inplace=True)\n",
    "                        \n",
    "#Remove rows with missing data\n",
    "#filtered_data_copy.dropna(inplace=True)\n",
    "print(\"Shape of the dataset with radiomic features : \" , np.shape(filtered_data_copy))\n",
    "#remove a batch level with only one sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17d13e1d-38f5-405a-a6e1-43bbb1c19aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n",
      "Int64Index([], dtype='int64')\n",
      "(95, 1238)\n"
     ]
    }
   ],
   "source": [
    "# Store the feature names\n",
    "feature_names = filtered_data_copy.columns.tolist()\n",
    "\n",
    "#specify the batch list                                            \n",
    "batch_list = ['model', 'kernel', 'slice_thickness']\n",
    "# specify the categorical and continous clinical covariates\n",
    "categorical_cols = ['Smoking', 'Sex']\n",
    "\n",
    "continuous_cols = ['Age']\n",
    "patient_name = filtered_data_copy['PatientName']\n",
    "\n",
    "# Initialize an empty mask (series of False values)\n",
    "# This will be used to mark rows to drop\n",
    "rows_to_drop = pd.Series(False, index=filtered_data_copy.index)\n",
    "\n",
    "# Loop over each categorical column\n",
    "for col in batch_list:\n",
    "    # Calculate the value counts for the current column\n",
    "    value_counts = filtered_data_copy[col].value_counts()\n",
    "    \n",
    "    # Identify values that occur exactly once\n",
    "    values_to_drop = value_counts[value_counts == 1].index\n",
    "    \n",
    "    # Update the mask to include rows where the current column's value is in values_to_drop\n",
    "    rows_to_drop |= filtered_data_copy[col].isin(values_to_drop)\n",
    "    print(values_to_drop)\n",
    "\n",
    "#remove batch levels with only one sample\n",
    "# Drop rows marked in the mask\n",
    "filtered_data_copy = filtered_data_copy[~rows_to_drop]\n",
    "print(np.shape(filtered_data_copy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6349db1-9960-4e88-8cac-2559272a2ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String-based covariate datframe :            Smoking     Sex          model kernel  slice_thickness\n",
      "0          Smoker    Male     Definition   B40f                1\n",
      "1          Smoker    Male     Definition   B40f                1\n",
      "2   Former smoker  Female     Definition   B40f                1\n",
      "3          Smoker  Female     Definition   B40f                1\n",
      "4          Smoker  Female     Definition   B40f                1\n",
      "..            ...     ...            ...    ...              ...\n",
      "90  Former smoker  Female  SOMATOM Drive  Br43f                2\n",
      "91  Former smoker  Female  SOMATOM Drive  Br43f                2\n",
      "92  Former smoker  Female  SOMATOM Drive  Br43f                2\n",
      "93     Non smoker  Female  SOMATOM Drive  Br43f                2\n",
      "94  Former smoker  Female  SOMATOM Drive  Br43f                2\n",
      "\n",
      "[95 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#define a string-based covariate datframe                       \n",
    "covars_string = pd.DataFrame()\n",
    "covars_string[categorical_cols] = filtered_data_copy[categorical_cols].copy()\n",
    "covars_string[batch_list] = filtered_data_copy[batch_list].copy()\n",
    "\n",
    "# Find the counts of each unique value in the batch column\n",
    "#value_counts = covars_string[batch_list].value_counts()\n",
    "\n",
    "# Extract the values that are repeated more than once\n",
    "#repeated_values = value_counts[value_counts > 1].index.tolist()\n",
    "\n",
    "# Display the values that are repeated\n",
    "#print(\"Repeated Values:\")\n",
    "#print(repeated_values)\n",
    "\n",
    "# Define the bins and labels for the categories of the batch column with continous value\n",
    "#bins = [0, 2, 4, 5]\n",
    "#labels = [1, 2, 3]\n",
    "\n",
    "# Create a new column with categories based on value ranges\n",
    "#covars_string['slice_thickness_new'] = pd.cut(covars_string[batch_list[-1]], bins=bins, labels=labels, include_lowest=True)\n",
    "#batch_list = ['slice_thickness_new']\n",
    "#covars_string.drop(columns=['slice_thickness'], inplace=True)\n",
    "# Display the DataFrame with the new category column\n",
    "print(\"String-based covariate datframe : \", covars_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c239cbf-acc6-47ae-af4a-9bb258ae225a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 6\n",
      "2: 89\n"
     ]
    }
   ],
   "source": [
    "counts_batch_levels = Counter(list(covars_string[\"slice_thickness\"]))\n",
    "\n",
    "for element, count in sorted(counts_batch_levels.items()):\n",
    "    print(f\"{element}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63a49fcb-4213-49ba-be37-0b8dd3519632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition: 20\n",
      "SOMATOM Definition: 70\n",
      "SOMATOM Drive: 5\n"
     ]
    }
   ],
   "source": [
    "counts_batch_levels = Counter(list(covars_string[\"model\"]))\n",
    "\n",
    "for element, count in sorted(counts_batch_levels.items()):\n",
    "    print(f\"{element}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46947c0d-b0c2-4429-8a41-193ae56ac4be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B40f: 90\n",
      "Br43f: 5\n"
     ]
    }
   ],
   "source": [
    "counts_batch_levels = Counter(list(covars_string[\"kernel\"]))\n",
    "\n",
    "for element, count in sorted(counts_batch_levels.items()):\n",
    "    print(f\"{element}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e963f4b-27c9-4ac6-afa3-5c14a7490f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#load the continous clinical covariate                       \n",
    "covars_quant = filtered_data_copy[continuous_cols]\n",
    "\n",
    "#specify the features\n",
    "data_df = filtered_data_copy.drop(columns=['PatientName', 'Smoking', 'Age', 'Sex', 'model', 'kernel', 'slice_thickness'])\n",
    "print(np.sum(np.sum(np.isnan(data_df))))\n",
    "#np.sum(np.sum(np.isnan(filtered_data_copy)))\n",
    "#nan_counts = data_df.isna().sum()\n",
    "#print(nan_counts[nan_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78d665d5-92a2-4eaf-b0bd-2c2556152ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230, 95)\n",
      "(95, 5)\n",
      "Index(['Smoking', 'Sex', 'model', 'kernel', 'slice_thickness'], dtype='object')\n",
      "(95, 1)\n",
      "Index(['Age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Remove constant radiomic features\n",
    "constant_features = data_df.columns[data_df.nunique() == 1]\n",
    "data_df.drop(constant_features, axis=1, inplace=True)\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "#dat = data_df.T\n",
    "dat = data_df.T.apply(pd.to_numeric)                        \n",
    "#print(dat)\n",
    "#label-encode the string covariates\n",
    "covars_cat = pd.DataFrame()\n",
    "\n",
    "for col in covars_string:\n",
    "    stringcol = covars_string[col]\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(stringcol))\n",
    "    covars_cat[col] = le.transform(stringcol)\n",
    "#print(np.shape(data_df))\n",
    "print(np.shape(dat))\n",
    "print(np.shape(covars_cat))\n",
    "print(covars_cat.columns)\n",
    "print(np.shape(covars_quant))\n",
    "print(covars_quant.columns)\n",
    "#print(len(covars_cat[batch_list[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef37446d-c9ac-4b01-ad9b-c87e6576a956",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Smoking  Sex  model  kernel  slice_thickness\n",
      "0         3    1      0       0                0\n",
      "1         3    1      0       0                0\n",
      "2         0    0      0       0                0\n",
      "3         3    0      0       0                0\n",
      "4         3    0      0       0                0\n",
      "..      ...  ...    ...     ...              ...\n",
      "90        0    0      2       1                1\n",
      "91        0    0      2       1                1\n",
      "92        0    0      2       1                1\n",
      "93        1    0      2       1                1\n",
      "94        0    0      2       1                1\n",
      "\n",
      "[95 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(covars_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7732bc6b-7085-497b-8965-4adf2766f516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Smoking', 'Sex']\n",
      "['Age']\n",
      "Number of NaN values in covars: 0\n"
     ]
    }
   ],
   "source": [
    "covars_cat_reset = covars_cat.reset_index(drop=True)\n",
    "covars_quant_reset = covars_quant.reset_index(drop=True)\n",
    "\n",
    "#concatenate the label-enoded categorical (batch+clinical) and continous clinical covariates                         \n",
    "covars = pd.concat([covars_cat_reset, covars_quant_reset], axis=1)\n",
    "print(categorical_cols)\n",
    "print(continuous_cols)\n",
    "#print(covars)\n",
    "# Check if there are any NaN values in covars and batch_col\n",
    "covars_nan_count = np.sum(np.sum(np.isnan(data_df)))\n",
    "#batch_col_nan_count = np.sum(np.isnan(batch_col))\n",
    "\n",
    "print(\"Number of NaN values in covars:\", covars_nan_count)\n",
    "#print(\"Number of NaN values in batch_col:\", batch_col_nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "913d9cbb-705f-4b5e-8dec-339f9dc477d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230, 95)\n",
      "ROUND 1:\n",
      "Harmonizing by model...\n",
      "ComBat with Raw Data...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "Harmonizing by kernel...\n",
      "ComBat with Raw Data...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "Harmonizing by slice_thickness...\n",
      "ComBat with Raw Data...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "ROUND 2:\n",
      "Harmonizing by model...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "Harmonizing by slice_thickness...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "ROUND 3:\n",
      "Harmonizing by slice_thickness...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(dat))\n",
    "#Nested Combat\n",
    "output_data = nested.NestedComBat(dat, covars, batch_list, categorical_cols=categorical_cols,\n",
    "                                   continuous_cols=continuous_cols, drop=True, write_p=False, filepath=main_dir)\n",
    "output_data_reset = output_data.reset_index(drop=True)\n",
    "patient_name_reset = patient_name.reset_index(drop=True)\n",
    "write_df = pd.concat([patient_name_reset, output_data_reset], axis=1)\n",
    "write_df.to_csv(os.path.join(main_dir,'results/data_combat/combat_harmonized_features_nested_cnet_updated_bw_0.05_D.csv'), float_format='%.7f', index= False)\n",
    "\n",
    "\n",
    "#Combat\n",
    "#data_combat = nC.neuroCombat(dat= dat.values,\n",
    "#                          covars=covars,\n",
    "#                          batch_col=batch_list[0]\n",
    "#                          ,categorical_cols=categorical_cols,\n",
    "#                          continuous_cols=continuous_cols\n",
    "#                            )[\"data\"]\n",
    "#pd.DataFrame(data_combat).to_csv(os.path.join(main_dir,'data_combat/combat_harmonized_features_slice_new.csv'), float_format='%.7f', index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cf0ab17-bda0-4559-bcf7-926e549f19d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "                       \n",
    "#nested.feature_kstest_histograms(output_data, covars, batch_list, main_dir)\n",
    "\n",
    "#f_dict = nested.MultiComBat(output_data.T, covars, batch_list, filepath=main_dir, categorical_cols=categorical_cols,\n",
    "#                          continuous_cols=continuous_cols, write_p=True, plotting=True)\n",
    "#for col in batch_list:\n",
    "#    write_df = pd.concat([patient_name, f_dict[col]])\n",
    "#    write_df.to_csv(os.path.join(main_dir, 'data_combat/combat_'+col+'_harmonized_features.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
