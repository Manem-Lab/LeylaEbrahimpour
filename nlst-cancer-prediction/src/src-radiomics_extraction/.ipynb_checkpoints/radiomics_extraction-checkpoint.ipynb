{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f57278-b75f-4cf2-b910-fbf5c9f45673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "from radiomics import featureextractor, getTestCase\n",
    "from radiomics.featureextractor import RadiomicsFeatureExtractor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt \n",
    "import pydicom\n",
    "from pydicom import dcmread\n",
    "import dicom2nifti\n",
    "import pydicom_seg\n",
    "import io\n",
    "import tempfile\n",
    "import gc\n",
    "import time\n",
    "import shutil\n",
    "from dicomweb_client.api import DICOMwebClient\n",
    "import dicom2nifti.settings as settings\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import nibabel as nib\n",
    "settings. disable_validate_slice_increment()\n",
    "#pydicom.config.pixel_data_handlers = ['gdcm_handler']\n",
    "# get the start timen_jobs\n",
    "\n",
    "st = time.time()\n",
    "#tmp_dir = os.getenv(\"SLURM_TMPDIR\")                \n",
    "# Define the float format\n",
    "float_format = '%.5f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04441d9-b43b-47cb-8f09-19d1d56ee91a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n",
      "empty response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Studies with this ID : 510\n"
     ]
    }
   ],
   "source": [
    "#path the main directory\n",
    "main_dir= \"/home/ulaval.ca/lesee/projects/Project-NLST/\"\n",
    "main_dir_seg = \"/project/166726187/NLST-mask/C1_nii_unzip\"\n",
    "\n",
    "\n",
    "\n",
    "#path of parameter file which includes the settings for radiomics extraction\n",
    "params = '/project/166726142/lesee/Synergic-Radiomics/src/Params_test.yaml'\n",
    "auth_token= 'kkaPH62MZeS01bqNeCBDDO'\n",
    "header = {'Authorization': 'Bearer ' + auth_token}\n",
    "\n",
    "#giving the path of web-based dicom files\n",
    "url=\"https://platform.paradim.science/api\"\n",
    "client_dcm = DICOMwebClient(url = url, headers = header)\n",
    "\n",
    "all_studies =[]\n",
    "data = pd.read_csv(os.path.join(main_dir,'data/data_batch-clinical-labels/Cohort1_labels.csv'))\n",
    "\n",
    "#patient_ids = [\"123459\"]\n",
    "patient_ids = data['PatientID']\n",
    "for patient_id in patient_ids:\n",
    "    search_filters = {'PatientID': patient_id}\n",
    "    studies = client_dcm.search_for_studies(search_filters=search_filters)\n",
    "    all_studies.extend(studies)\n",
    "print(\"Number of Studies with this ID :\", len(all_studies))\n",
    "      \n",
    "#find the first 'limit' number of studies  \n",
    "#studies = client_dcm.search_for_studies()\n",
    "#studies = client_dcm.search_for_studies(limit = 1000, get_remaining=False)\n",
    "#studies = client_dcm.search_for_studies(offset=1290)\n",
    "studies_dicom = [pydicom.dataset.Dataset.from_json(d) for d in all_studies]\n",
    "\n",
    "CT_modality = ['CT']\n",
    "data_features =[]\n",
    "index_studies =[]\n",
    "index_studies_10_ct_slice = []\n",
    "date_studies_10_ct_slice = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354a632-04e1-4259-a02d-ce25403970db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study No. =  1\n",
      "Patient ID =  100012\n",
      "Study Date =  20000102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.135088253786049275791463451273034430925\n",
      "Number of maximum Slices = 157\n",
      "Number of segmentation Slices = 157\n",
      "Study No. =  2\n",
      "Patient ID =  100012\n",
      "Study Date =  19990102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.335938848402215862539398120263494500079\n",
      "Number of maximum Slices = 162\n",
      "Number of segmentation Slices = 162\n",
      "Study No. =  3\n",
      "Patient ID =  100147\n",
      "Study Date =  20000102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.157089410086487452104998883963678895145\n",
      "Number of maximum Slices = 116\n",
      "Number of segmentation Slices = 116\n",
      "Study No. =  4\n",
      "Patient ID =  100147\n",
      "Study Date =  19990102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.247854884634057477137769379611681725965\n",
      "Number of maximum Slices = 110\n",
      "Number of segmentation Slices = 110\n",
      "Study No. =  5\n",
      "Patient ID =  100186\n",
      "Study Date =  20010102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.30323438322867280216766659410513099972\n",
      "No mask for Patient ID 100186 with Study Date 20010102\n",
      "Study No. =  6\n",
      "Patient ID =  100186\n",
      "Study Date =  20000102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing duplicate slice from series\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.95390133820800676175811787332322515581\n",
      "Number of maximum Slices = 168\n",
      "Number of segmentation Slices = 168\n",
      "Study No. =  7\n",
      "Patient ID =  100186\n",
      "Study Date =  19990102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.172536608767939874106861342401532685714\n",
      "Number of maximum Slices = 165\n",
      "Number of segmentation Slices = 165\n",
      "Study No. =  8\n",
      "Patient ID =  100913\n",
      "Study Date =  20000102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.242872001730153655612828839900351935159\n",
      "Number of maximum Slices = 120\n",
      "Number of segmentation Slices = 120\n",
      "Study No. =  9\n",
      "Patient ID =  100913\n",
      "Study Date =  19990102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.174991376308915374668412349017559749438\n",
      "Number of maximum Slices = 119\n",
      "Number of segmentation Slices = 119\n",
      "Study No. =  10\n",
      "Patient ID =  100954\n",
      "Study Date =  20000102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.221431020285713410688184350160835123791\n",
      "Number of maximum Slices = 151\n",
      "Number of segmentation Slices = 151\n",
      "Study No. =  11\n",
      "Patient ID =  100954\n",
      "Study Date =  19990102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.62533278088124927801007016244677857799\n",
      "Number of maximum Slices = 160\n",
      "Number of segmentation Slices = 160\n",
      "Study No. =  12\n",
      "Patient ID =  100965\n",
      "Study Date =  20010102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.334356542844484154488913523887503456543\n",
      "No mask for Patient ID 100965 with Study Date 20010102\n",
      "Study No. =  13\n",
      "Patient ID =  100965\n",
      "Study Date =  20000102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.256401971960428674995403668801997713309\n",
      "Number of maximum Slices = 133\n",
      "Number of segmentation Slices = 133\n",
      "Study No. =  14\n",
      "Patient ID =  100965\n",
      "Study Date =  19990102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.157153278473135611830346300699144721894\n",
      "Number of maximum Slices = 129\n",
      "Number of segmentation Slices = 129\n",
      "Study No. =  15\n",
      "Patient ID =  101012\n",
      "Study Date =  20010102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.196667023339883202833146472634093593777\n",
      "No mask for Patient ID 101012 with Study Date 20010102\n",
      "Study No. =  16\n",
      "Patient ID =  101012\n",
      "Study Date =  20000102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.301053018286636750598221311313824181939\n",
      "Number of maximum Slices = 197\n",
      "Number of segmentation Slices = 197\n",
      "Study No. =  17\n",
      "Patient ID =  101012\n",
      "Study Date =  19990102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.129278905845996038456153205223151646340\n",
      "Number of maximum Slices = 177\n",
      "Number of segmentation Slices = 177\n",
      "Study No. =  18\n",
      "Patient ID =  101068\n",
      "Study Date =  20000102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.174815865605540072126627846390000187679\n",
      "Number of maximum Slices = 157\n",
      "Number of segmentation Slices = 157\n",
      "Study No. =  19\n",
      "Patient ID =  101068\n",
      "Study Date =  19990102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.103714918441192153265294170977914772968\n",
      "Number of maximum Slices = 140\n",
      "Number of segmentation Slices = 140\n",
      "Study No. =  20\n",
      "Patient ID =  101444\n",
      "Study Date =  20010102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.337580920938978568742299540150131650998\n",
      "No mask for Patient ID 101444 with Study Date 20010102\n",
      "Study No. =  21\n",
      "Patient ID =  101444\n",
      "Study Date =  20000102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.315378861785700800362905815253058416034\n",
      "Number of maximum Slices = 197\n",
      "Number of segmentation Slices = 197\n",
      "Study No. =  22\n",
      "Patient ID =  101444\n",
      "Study Date =  19990102\n",
      "Serie ID with maximum number of slices: 1.2.840.113654.2.55.80943581773335100101523227709637814819\n",
      "Number of maximum Slices = 198\n",
      "Number of segmentation Slices = 197\n",
      "Study No. =  23\n",
      "Patient ID =  101467\n",
      "Study Date =  20010102\n"
     ]
    }
   ],
   "source": [
    "for num_std , study_dicom in enumerate(studies_dicom): \n",
    "    try: \n",
    "        #find the series instance ID from SEG file in each study\n",
    "        study_instance_uid = study_dicom['StudyInstanceUID'].value\n",
    "        study_date = study_dicom['StudyDate'].value\n",
    "        patient_ID = study_dicom['PatientID'].value\n",
    "        patient_name = study_dicom['PatientName'].value  \n",
    "        print('Study No. = ', num_std+1 )\n",
    "        print('Patient ID = ', patient_ID )\n",
    "        print('Study Date = ', study_date )\n",
    "    #    metadata_study = client_dcm.retrieve_study_metadata(study_instance_uid = study_instance_uid)\n",
    "    #        modality_values = study_dicom[\"00080061\"]\n",
    "    #        print(\"Modality Values:\", modality_values)\n",
    "\n",
    "\n",
    "        series = client_dcm.search_for_series(study_instance_uid=study_instance_uid)           \n",
    "    #    num_CT = 0\n",
    "    #    series_len_instances= []\n",
    "    #    series_instance_uid = []\n",
    "        max_slices = 10\n",
    "        series_with_max_slices = None\n",
    "        for ind, serie in enumerate(series):\n",
    "            series_CT_dicom = pydicom.dataset.Dataset.from_json(serie)\n",
    "            if series_CT_dicom.Modality in CT_modality:\n",
    "    #                num_CT +=1      \n",
    "                instances_ct = client_dcm.retrieve_series(study_instance_uid = study_instance_uid, \n",
    "                                                          series_instance_uid = series_CT_dicom['SeriesInstanceUID'].value)\n",
    "                num_slices = len(instances_ct)\n",
    "                if num_slices > max_slices:\n",
    "                    max_slices = num_slices\n",
    "                    series_with_max_slices = serie\n",
    "                    series_with_max_slices_instance_uid = series_CT_dicom['SeriesInstanceUID'].value\n",
    "                    instances_ct_with_max_slices = instances_ct\n",
    "                    convolution_kernel_with_max_slices = instances_ct[0][0x00181210].value\n",
    "                    \n",
    "                    \n",
    "        if max_slices ==10:\n",
    "            index_studies_10_ct_slice.append(patient_ID)\n",
    "            date_studies_10_ct_slice.append(study_date)\n",
    "            continue\n",
    "\n",
    "\n",
    "        print(\"Serie ID with maximum number of slices:\", series_with_max_slices_instance_uid)\n",
    "        #convert the CT dicom images to one nifti file\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:      \n",
    "            img_CT = dicom2nifti.convert_dicom.dicom_array_to_nifti(instances_ct_with_max_slices,os.path.join(tmp_dir+'_CT.nii'), reorient_nifti=True)[\"NII\"]\n",
    "            CT_nifti_path = os.path.join(tmp_dir+'_CT.nii')                            \n",
    "            #read the CT nifit as a sitk image file                 \n",
    "            img_CT_stk = sitk.ReadImage(CT_nifti_path)\n",
    "        #remove the temporary nifti file after reading\n",
    "            os.remove(CT_nifti_path)\n",
    "\n",
    "        # check if there is any segmentation file for this study\n",
    "        if study_date == \"19990102\":\n",
    "        # Pattern to match the subfolder\n",
    "            subfolder_seg_pattern_T0 = os.path.join(main_dir_seg, f'*{patient_ID}*_T0.nii')\n",
    "            subfolder_seg_T0 = glob.glob(subfolder_seg_pattern_T0)[0]  # Take the first matching subfolder\n",
    "            # Pattern to match the NIfTI file within the subfolder\n",
    "            nifti_seg_file_pattern_T0 = os.path.join(subfolder_seg_T0, f'*{patient_ID}*T0.nii')\n",
    "            nifti_seg_file_path= glob.glob(nifti_seg_file_pattern_T0)[0]  # Take the first matching file\n",
    "#            nifti_file = nib.load(nifti_seg_file_path)\n",
    "#            print(nifti_file.header)\n",
    "\n",
    "\n",
    "        elif study_date == \"20000102\":\n",
    "\n",
    "        # Pattern to match the subfolder\n",
    "            subfolder_seg_pattern_T1 = os.path.join(main_dir_seg, f'*{patient_ID}*_T1.nii') \n",
    "            subfolder_seg_T1 = glob.glob(subfolder_seg_pattern_T1)[0]  # Take the first matching subfolder                    \n",
    "            # Pattern to match the NIfTI file within the subfolder\n",
    "            nifti_seg_file_pattern_T1 = os.path.join(subfolder_seg_T1, f'*{patient_ID}*T1.nii')\n",
    "            nifti_seg_file_path= glob.glob(nifti_seg_file_pattern_T1)[0]  # Take the first matching file \n",
    "#            nifti_file = nib.load(nifti_seg_file_path)\n",
    "#            print(nifti_file.header)\n",
    "            \n",
    "\n",
    "#        elif study_date == \"20010102\":\n",
    "        # Pattern to match the subfolder\n",
    "#            subfolder_seg_pattern_T2 = os.path.join(main_dir_seg, f'*{patient_ID}*_T2.nii')                    \n",
    "#            subfolder_seg_T2 = glob.glob(subfolder_seg_pattern_T2)[0]  # Take the first matching subfolder                                            \n",
    "            # Pattern to match the NIfTI file within the subfolder\n",
    "#            nifti_seg_file_pattern_T2 = os.path.join(subfolder_seg_T2, f'*{patient_ID}*T2.nii')                        \n",
    "#            nifti_seg_file_path= glob.glob(nifti_seg_file_pattern_T2)[0]  # Take the first matching file   \n",
    "#            nifti_file = nib.load(nifti_seg_file_path)\n",
    "#            print(nifti_file.header)\n",
    "            \n",
    "        else: \n",
    "\n",
    "            print (\"No mask for Patient ID \" + str(patient_ID)+\" with Study Date \"+ str (study_date))\n",
    "            continue\n",
    "\n",
    "            #read the seg nifit as a sitk image file\n",
    "        img_mask = sitk.ReadImage(nifti_seg_file_path)\n",
    "        mask_array = sitk.GetArrayFromImage(img_mask)\n",
    "\n",
    "        print(\"Number of maximum Slices =\", max_slices)\n",
    "        print(\"Number of segmentation Slices =\", len(mask_array))\n",
    "\n",
    "        # Extract radiomic features\n",
    "        extractor = featureextractor.RadiomicsFeatureExtractor(params, additionalInfo=True)\n",
    "        extractor.settings['n_jobs'] = -1\n",
    "    #   features = extractor.execute(img_CT_stk, img_seg_resampled, label=int(labels_resampled[-1]))\n",
    "    #    features = extractor.execute(img_CT_stk, img_mask, label=int(tumor_segment_number))\n",
    "        features = extractor.execute(img_CT_stk, img_mask, label = 1)\n",
    "        features_key = ['PatientName', 'PatientID', 'StudyDate', 'kernel', 'CtSlices', 'SegSlices', 'StudyInstanceUID', 'SeriesInstanceUID']\n",
    "        features_value = [patient_name, patient_ID, study_date, convolution_kernel_with_max_slices, max_slices, len(mask_array), study_instance_uid, series_with_max_slices_instance_uid]\n",
    "        for num , (key, val) in enumerate(six.iteritems(features)):\n",
    "            features_key.append(key)\n",
    "            features_value.append(val)\n",
    "        data_features.append(features_value)\n",
    "        index_studies.append(num_std+1)\n",
    "    #                    break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    #print(features_key)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f5b770-e8a4-4f4c-981d-b9cb090b3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# write into excel      \n",
    "#writer = pd.ExcelWriter(os.path.join(main_dir,'results/radiomicsfeatures_kheops-NLST-Dmitrii-max_slice_Cohort1_repeat.xlsx'), engine='xlsxwriter')\n",
    "\n",
    "\n",
    "#wb  = writer.book\n",
    "df_features = pd.DataFrame(data=data_features, index = index_studies, columns=features_key)\n",
    "df_features.to_csv(os.path.join(main_dir,'results/radiomicsfeatures_kheops-NLST-Dmitrii-max_slice_Cohort1_repeat.csv'))\n",
    "#df_features.to_excel(writer, sheet_name=\"radiomic features\")                                     \n",
    "#wb.close()\n",
    "\n",
    "\n",
    "# Create a DataFrame for studies with maximum 10 CT slices\n",
    "df_10_slices = pd.DataFrame({\n",
    "    'PatientID': index_studies_10_ct_slice,\n",
    "    'StudyDate': date_studies_10_ct_slice\n",
    "})\n",
    "\n",
    "# To save as CSV\n",
    "df_10_slices.to_csv(os.path.join(main_dir,'results/10_slices-NLST-Dmitrii-max_slice_Cohort1_repeat.csv'), index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
