{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b245837e-cf6a-4b3b-9973-fdea326f1679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neuroCombat as nC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ranksums, ttest_ind, ttest_rel, ks_2samp\n",
    "import os\n",
    "import Nestedcombat as nested\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#import GMMComBat as gmmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad09b87-a265-4188-93a1-006d1b213949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1694, 1239)\n",
      "(1959, 14)\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "main_dir= \"/home/ulaval.ca/lesee/projects/Project-NLST/\"\n",
    "\n",
    "#features_cohort1_T0 = pd.read_csv(os.path.join(main_dir,'data/radiomicsfeatures_kheops-NLST-Dmitrii-Cohort2_Laptop_v2-cleaned-T2-ML.csv'))\n",
    "#batch_cohort1_T0 = pd.read_csv(os.path.join(main_dir,'data/cohort2-T2-batch.csv'))\n",
    "#clinical_cohort1_T0 = pd.read_csv(os.path.join(main_dir,'data/Cohort2_clinical.csv'))\n",
    "features = pd.read_csv(os.path.join(main_dir,'data/radiomicsfeatures_kheops-NLST-Dmitrii-Cohort1_2_Laptop_v2.csv'))\n",
    "batch = pd.read_csv(os.path.join(main_dir,'data/combat_params_cohort1_2.csv'))\n",
    "clinical = pd.read_csv(os.path.join(main_dir,'data/Cohort1_2_clinical.csv'))\n",
    "print(np.shape(features))\n",
    "print(np.shape(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74da39b3-eba4-41c1-b423-de2ee145bb7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STANDARD', 'B50f', 'B30f', 'BONE', 'C', 'D', 'LUNG', 'FC51', 'FC10',\n",
      "       'FC30', 'B', 'FC02', 'A', 'B80f', 'FC01', 'B60f', 'B50s', 'B30s',\n",
      "       'FC50', 'B70f', 'FC82'],\n",
      "      dtype='object')\n",
      "Float64Index([2.5, 2.0, 3.2, 1.25, 1.0, 3.0, 1.3], dtype='float64')\n",
      "Index(['GE MEDICAL SYSTEMS', 'SIEMENS', 'Philips', 'TOSHIBA'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "value_counts = batch['ConvolutionKernel'].value_counts()\n",
    "# Identify values that occur exactly once\n",
    "print(value_counts.index)\n",
    "value_counts = batch['SliceThickness'].value_counts()\n",
    "# Identify values that occur exactly once\n",
    "print(value_counts.index)\n",
    "value_counts = batch['Manufacturer'].value_counts()\n",
    "# Identify values that occur exactly once\n",
    "print(value_counts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a271727-6aeb-4481-b17d-706525b51020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the custom function to categorize the kernel types\n",
    "def categorize_kernel(kernel):\n",
    "    sharp_kernels = ['BONE', 'B80f', 'B60f', 'B50f', 'B30f', 'LUNG', 'B70f', 'B50s', 'B30s']\n",
    "    soft_kernels = ['STANDARD', 'C', 'D', 'B', 'FC51', 'FC10', 'FC30', 'FC02', 'FC01', 'A', 'FC50', 'FC82']\n",
    "    \n",
    "    \n",
    "    if kernel in sharp_kernels:\n",
    "        return 'Sharp'\n",
    "    elif kernel in soft_kernels:\n",
    "        return 'Soft'\n",
    "    else:\n",
    "        return 'Unknown'  # For any values not explicitly listed\n",
    "    \n",
    "# Define the function for categorization\n",
    "def categorize_thickness(thickness):\n",
    "    if thickness < 1.5:\n",
    "        return 'Thin'\n",
    "    elif thickness <= 3.0:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Thick'\n",
    "\n",
    "# Apply the function to create a new column\n",
    "batch['ThicknessCategory'] = batch['SliceThickness'].apply(categorize_thickness)\n",
    "\n",
    "\n",
    "# Apply the function to the original column to create a new one\n",
    "batch['KernelType'] = batch['ConvolutionKernel'].apply(categorize_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc677c03-7aab-48d0-8c6c-e39c7100828b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PatientID', 'StudyDate', 'StudyInstanceUID', 'SeriesInstanceUID',\n",
      "       'SeriesDescription', 'ImageType', 'Manufacturer', 'ModelName',\n",
      "       'ConvolutionKernel', 'ReconDiameter', 'SliceThickness', 'kVp', 'mAs',\n",
      "       'PixelSpacing', 'ThicknessCategory', 'KernelType'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(batch.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf02ffbf-5b54-4625-82fe-fb07c8a9a091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(batch_cohort1_T0.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee12741e-db6f-4cd2-b53c-a66b1917ab04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PatientID', 'StudyDate', 'SeriesDescription', 'Age', 'Smoking',\n",
      "       'De_Stag', 'Gender', 'Lesionsize', 'Race'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(clinical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e25064-7aca-4737-910b-cf57dbe82ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'PatientID', 'StudyDate_x', 'SeriesDescription_x',\n",
      "       'Kernel', 'CtSlices', 'SegSlices', 'SeriesInstanceUID',\n",
      "       'diagnostics_Image-original_Mean', 'diagnostics_Image-original_Minimum',\n",
      "       ...\n",
      "       'Manufacturer', 'ModelName', 'ConvolutionKernel', 'ReconDiameter',\n",
      "       'SliceThickness', 'kVp', 'mAs', 'PixelSpacing', 'ThicknessCategory',\n",
      "       'KernelType'],\n",
      "      dtype='object', length=1253)\n",
      "(1694, 1253)\n"
     ]
    }
   ],
   "source": [
    "match_column = 'PatientID'\n",
    "\n",
    "# Define the columns to match on as a list\n",
    "match_columns = ['PatientID', 'SeriesInstanceUID']\n",
    "\n",
    "#Perform the joins\n",
    "# First, merge df1 and df2\n",
    "#merged_df1_df2 = pd.merge(features_cohort1_T0, batch_cohort1_T0, on=match_column, how='outer')\n",
    "merged_df1_df2 = pd.merge(features, batch, on=match_columns, how='inner')\n",
    "print(merged_df1_df2.columns)\n",
    "print(np.shape(merged_df1_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da999d98-b320-4777-8dfd-470680d2057d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Then, merge the result with df3\n",
    "#cohort1_T0_rads_batch_clinical = pd.merge(merged_df1_df2, clinical_cohort1_T0, on=match_column, how='outer')\n",
    "cohort1_2_rads_batch_clinical = pd.merge(merged_df1_df2, clinical, on=match_column, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e113c40-1b4b-4b22-b60b-a61a01864b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'PatientID', 'StudyDate_x', 'SeriesDescription_x',\n",
      "       'Kernel', 'CtSlices', 'SegSlices', 'SeriesInstanceUID',\n",
      "       'diagnostics_Image-original_Mean', 'diagnostics_Image-original_Minimum',\n",
      "       ...\n",
      "       'ThicknessCategory', 'KernelType', 'StudyDate', 'SeriesDescription',\n",
      "       'Age', 'Smoking', 'De_Stag', 'Gender', 'Lesionsize', 'Race'],\n",
      "      dtype='object', length=1261)\n",
      "(1689, 1261)\n"
     ]
    }
   ],
   "source": [
    "print(cohort1_2_rads_batch_clinical.columns)\n",
    "print(np.shape(cohort1_2_rads_batch_clinical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02049658-0b32-4c92-9025-f3e5e856695a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "(1689, 1261)\n"
     ]
    }
   ],
   "source": [
    "#specify the batch list                                            \n",
    "#batch_list = ['Manufacturer', 'ModelName', 'ConvolutionKernel', 'SliceThickness']\n",
    "#batch_list = ['ThicknessCategory']\n",
    "batch_list = ['Manufacturer']\n",
    "# specify the categorical and continous clinical covariates\n",
    "categorical_cols = ['Smoking', 'Gender']\n",
    "\n",
    "continuous_cols = ['Age']\n",
    "\n",
    "# Explicitly create a copy of the data to work with\n",
    "filtered_data_copy = cohort1_2_rads_batch_clinical.copy()\n",
    "\n",
    "# Initialize an empty mask (series of False values)\n",
    "# This will be used to mark rows to drop\n",
    "rows_to_drop = pd.Series(False, index=filtered_data_copy.index)\n",
    "\n",
    "# Loop over each categorical column\n",
    "for col in batch_list:\n",
    "    # Calculate the value counts for the current column\n",
    "    value_counts = filtered_data_copy[col].value_counts()\n",
    "    \n",
    "    # Identify values that occur exactly once\n",
    "    values_to_drop = value_counts[value_counts == 1].index\n",
    "    \n",
    "    # Update the mask to include rows where the current column's value is in values_to_drop\n",
    "    rows_to_drop |= filtered_data_copy[col].isin(values_to_drop)\n",
    "    print(values_to_drop)\n",
    "\n",
    "#remove batch levels with only one sample\n",
    "# Drop rows marked in the mask\n",
    "filtered_data_copy = filtered_data_copy[~rows_to_drop]\n",
    "print(np.shape(filtered_data_copy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdc61a6-3dca-4f83-850b-f59e64376429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#drop columns not used in this work\n",
    "#filtered_data_copy.drop(columns = ['Center', 'pixel_spacing', 'StudyInstanceUID', 'Recurrence', 'OS_days', 'PFS_days', 'manufacturer'], inplace=True)\n",
    "                        \n",
    "#Remove rows with missing data\n",
    "#filtered_data_copy.dropna(inplace=True)\n",
    "#print(\"Shape of the dataset with radiomic features : \" , np.shape(filtered_data_copy))\n",
    "\n",
    "# Store the feature names\n",
    "feature_names = filtered_data_copy.columns.tolist()\n",
    "#print(feature_names)                    \n",
    "patient_name = filtered_data_copy['PatientID']     \n",
    "study_date = filtered_data_copy['StudyDate_x']\n",
    "series_uid = filtered_data_copy['SeriesInstanceUID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6349db1-9960-4e88-8cac-2559272a2ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String-based covariate columns :  Index(['Smoking', 'Gender', 'Manufacturer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#define a string-based covariate datframe                       \n",
    "covars_string = pd.DataFrame()\n",
    "covars_string[categorical_cols] = filtered_data_copy[categorical_cols].copy()\n",
    "covars_string[batch_list] = filtered_data_copy[batch_list].copy()\n",
    "print(\"String-based covariate columns : \", covars_string.columns)\n",
    "#print(list(filtered_data_copy.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "968deaae-095a-4991-8cc1-d3a5402a7fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1109, 1689)\n",
      "(1689, 3)\n",
      "Index(['Smoking', 'Gender', 'Manufacturer'], dtype='object')\n",
      "(1689, 1)\n",
      "Index(['Age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#load the continous clinical covariate                       \n",
    "covars_quant = filtered_data_copy[continuous_cols]\n",
    "\n",
    "#specify the features\n",
    "data_df = filtered_data_copy.drop(columns=['Unnamed: 0', 'PatientID', 'StudyDate_x', 'SeriesDescription_x', 'Kernel', \n",
    "                                           'CtSlices', 'SegSlices', 'SeriesInstanceUID', 'StudyDate_y', 'StudyInstanceUID',\n",
    "                                           'SeriesDescription_y', 'ImageType', 'Manufacturer', 'ModelName', 'ConvolutionKernel', \n",
    "                                           'ReconDiameter', 'SliceThickness', 'kVp', 'mAs', 'PixelSpacing', 'StudyDate', \n",
    "                                           'SeriesDescription', 'Age', 'Smoking', 'De_Stag', 'Gender', 'Lesionsize', 'Race',\n",
    "                                           'ThicknessCategory', 'KernelType'\n",
    "                                          ])\n",
    "\n",
    "\n",
    "\n",
    "#print(data_df.columns)\n",
    "#Remove constant radiomic features\n",
    "constant_features = data_df.columns[data_df.nunique() == 1]\n",
    "data_df.drop(constant_features, axis=1, inplace=True)\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "#dat = data_df.T\n",
    "dat = data_df.T.apply(pd.to_numeric)                        \n",
    "#print(dat)\n",
    "#label-encode the string covariates\n",
    "covars_cat = pd.DataFrame()\n",
    "\n",
    "\n",
    "for col in covars_string:\n",
    "    stringcol = covars_string[col]\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(stringcol))\n",
    "    covars_cat[col] = le.transform(stringcol)\n",
    "#print(np.shape(data_df))\n",
    "print(np.shape(dat))\n",
    "#print(data_df.columns)\n",
    "print(np.shape(covars_cat))\n",
    "print(covars_cat.columns)\n",
    "print(np.shape(covars_quant))\n",
    "print(covars_quant.columns)\n",
    "#print(len(covars_cat[batch_list[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7732bc6b-7085-497b-8965-4adf2766f516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Smoking', 'Gender']\n",
      "['Age']\n",
      "Number of NaN values in covars: 0\n"
     ]
    }
   ],
   "source": [
    "covars_cat_reset = covars_cat.reset_index(drop=True)\n",
    "covars_quant_reset = covars_quant.reset_index(drop=True)\n",
    "\n",
    "#concatenate the label-enoded categorical (batch+clinical) and continous clinical covariates                         \n",
    "covars = pd.concat([covars_cat_reset, covars_quant_reset], axis=1)\n",
    "print(categorical_cols)\n",
    "print(continuous_cols)\n",
    "#print(covars)\n",
    "# Check if there are any NaN values in covars and batch_col\n",
    "covars_nan_count = np.sum(np.sum(np.isnan(data_df)))\n",
    "#batch_col_nan_count = np.sum(np.isnan(batch_col))\n",
    "\n",
    "print(\"Number of NaN values in covars:\", covars_nan_count)\n",
    "#print(\"Number of NaN values in batch_col:\", batch_col_nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "913d9cbb-705f-4b5e-8dec-339f9dc477d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1109, 1689)\n",
      "ROUND 1:\n",
      "Harmonizing by KernelType...\n",
      "ComBat with Raw Data...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "Harmonizing by ThicknessCategory...\n",
      "ComBat with Raw Data...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "Harmonizing by Manufacturer...\n",
      "ComBat with Raw Data...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "ROUND 2:\n",
      "Harmonizing by ThicknessCategory...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "Harmonizing by Manufacturer...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "ROUND 3:\n",
      "Harmonizing by Manufacturer...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(dat))\n",
    "#Nested Combat\n",
    "output_data = nested.NestedComBat(dat, covars, batch_list, categorical_cols=categorical_cols,\n",
    "                                   continuous_cols=continuous_cols, drop=False, write_p=False, filepath=main_dir)\n",
    "output_data_reset = output_data.reset_index(drop=True)\n",
    "patient_name_reset = patient_name.reset_index(drop=True)\n",
    "study_date_reset = study_date.reset_index(drop=True)\n",
    "series_uid_reset = series_uid.reset_index(drop=True)\n",
    "write_df = pd.concat([patient_name_reset, study_date_reset,series_uid_reset, output_data_reset], axis=1)\n",
    "write_df.to_csv(os.path.join(main_dir,'results/cohort1_2_rads_combat_manufacturer_notdropped.csv'), float_format='%.7f', index= False)\n",
    "\n",
    "\n",
    "#Combat\n",
    "#data_combat = nC.neuroCombat(dat= dat.values,\n",
    "#                          covars=covars,\n",
    "#                          batch_col=batch_list[0]\n",
    "#                          ,categorical_cols=categorical_cols,\n",
    "#                          continuous_cols=continuous_cols\n",
    "#                            )[\"data\"]\n",
    "#pd.DataFrame(data_combat).to_csv(os.path.join(main_dir,'data_combat/combat_harmonized_features_slice_new.csv'), float_format='%.7f', index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cf0ab17-bda0-4559-bcf7-926e549f19d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "                       \n",
    "#nested.feature_kstest_histograms(output_data, covars, batch_list, main_dir)\n",
    "\n",
    "#f_dict = nested.MultiComBat(output_data.T, covars, batch_list, filepath=main_dir, categorical_cols=categorical_cols,\n",
    "#                          continuous_cols=continuous_cols, write_p=True, plotting=True)\n",
    "#for col in batch_list:\n",
    "#    write_df = pd.concat([patient_name, f_dict[col]])\n",
    "#    write_df.to_csv(os.path.join(main_dir, 'data_combat/combat_'+col+'_harmonized_features.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
