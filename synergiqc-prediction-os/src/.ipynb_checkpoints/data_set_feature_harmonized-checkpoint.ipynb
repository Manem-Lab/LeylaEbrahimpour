{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "badbf7db-a00b-4b4f-abbc-96016a6a544b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "241bdd15-96d5-4dbd-8827-33e7c2e76f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features =  (1000, 1408)\n"
     ]
    }
   ],
   "source": [
    "# get the start time\n",
    "st = time.time()\n",
    "file_name = 'T-OS_st1-2_rad_dataset-corr'\n",
    "#Load the data\n",
    "main_dir= \"/home/ulaval.ca/lesee/projects/Project2-synergiqc/OS/\"\n",
    "\n",
    "\n",
    "data = pd.read_excel(os.path.join(main_dir,'data/T-SynergiQc_annotated-clinical-radiomics1713-harmonized.xlsx'))\n",
    "# Identify and drop columns with all NaN values\n",
    "#data.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Filter the data for stage\n",
    "filtered_data = data[data['Stage'].isin([1,2])]\n",
    "\n",
    "# Explicitly create a copy of the data\n",
    "filtered_data_copy = filtered_data.copy()\n",
    "\n",
    "filtered_data_copy.drop(columns=['PatientName', 'PatientID', 'StudyInstanceUID', 'Stage', 'Recurrence', 'PFS-months', 'PFS-days'], inplace=True)\n",
    "\n",
    "#Remove rows with missing data\n",
    "filtered_data_copy.dropna(inplace=True)\n",
    "                                            \n",
    "features = filtered_data_copy.drop(columns=['OS-months', 'OS-days'])\n",
    "print(\"number of features = \", np.shape(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cbd06d2-9d7b-4810-aa43-782eed092b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the target variable for stage 1 and stage 2\n",
    "target = filtered_data_copy['OS-months']\n",
    "#event = filtered_data_copy['VitalStatus']\n",
    "#print(\"number of features = \", np.shape(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a32dd414-cd5c-4a19-9601-d10f421c1949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313\n"
     ]
    }
   ],
   "source": [
    "#Remove constant radiomic features\n",
    "#constant_features = features.columns[features.nunique() == 1]\n",
    "#features.drop(constant_features, axis=1, inplace=True)\n",
    "features = features.loc[:, features.var() != 0.0]\n",
    "\n",
    "# Store the feature names\n",
    "feature_names = features.columns.tolist()\n",
    "print(len(feature_names))\n",
    "#print(feature_names)\n",
    "#print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b0ff046-14f6-479c-b239-037de12ff0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1313)\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "# Define the list of clinical columns to drop\n",
    "columns_clinical_to_drop = ['Smoking', 'Age', 'Subtype', 'Sex', 'VitalStatus']\n",
    "# Filter LoG features \n",
    "log_features = [feature for feature in feature_names if \"log-sigma\" in feature ]\n",
    "\n",
    "\n",
    "# Filter intensity_based features from original image\n",
    "intensity_original_features = [feature for feature in feature_names if \"_firstorder_\" in feature and feature.startswith(\"original\")]\n",
    "#print(intensity_original_features)\n",
    "# Filter texture_based features from original image\n",
    "texture_original_features = [feature for feature in feature_names if (\"_glcm_\" in feature or \"_gldm_\" in feature or \"_glrlm_\" in feature or \"_glszm_\" in feature) and feature.startswith(\"original\")]\n",
    "# Filter wavelet_based features\n",
    "wavelet_features = [feature for feature in feature_names if \"wavelet\" in feature]\n",
    "# Filter intensity_based features\n",
    "intensity_features = [feature for feature in feature_names if \"_firstorder_\" in feature]\n",
    "# Filter texture_based features\n",
    "texture_features = [feature for feature in feature_names if (\"_glcm_\" in feature or \"_gldm_\" in feature or \"_glrlm_\" in feature or \"_glszm_\" in feature)]\n",
    "# Filter shape_based features\n",
    "shape_features = [feature for feature in feature_names if \"_shape_\" in feature]\n",
    "\n",
    "X_rads = features\n",
    "print(np.shape(X_rads))\n",
    "print(len(log_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdc3a7dc-61af-42e0-b59e-274341d5659c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training features = (700, 172)\n",
      "Shape of the test features = (300, 172)\n"
     ]
    }
   ],
   "source": [
    "#select desired features from the whole dataset based on the type of radiomics\n",
    "X_rads_intensity_original = X_rads[intensity_original_features]\n",
    "X_rads_texture_original = X_rads[texture_original_features]\n",
    "X_rads_wavelet = X_rads[wavelet_features]\n",
    "X_rads_intensity = X_rads[intensity_features]\n",
    "X_rads_texture = X_rads[texture_features]\n",
    "X_rads_shape = X_rads[shape_features]\n",
    "X_rads_LoG = X_rads[log_features]\n",
    "X_clinical = X_rads[columns_clinical_to_drop]\n",
    "X_rads_clinical = np.concatenate((X_rads_LoG, X_clinical), axis=1)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_rads_clinical, target, test_size=0.3, random_state=42)\n",
    "# Drop the last four columns (assuming they are clinical data)\n",
    "X_train_filtered = X_train[:, :-5]\n",
    "X_test_filtered = X_test[:, :-5]\n",
    "# Keep only the last four columns (assuming they are clinical data)\n",
    "X_train_clinical = X_train[:, -5:]\n",
    "X_test_clinical = X_test[:, -5:]\n",
    "\n",
    "#print(X_rads_LoG)\n",
    "print(\"Shape of the training features =\", np.shape(X_train_filtered))\n",
    "print(\"Shape of the test features =\", np.shape(X_test_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eecf01de-de3b-4d13-b518-efc472389c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training features after removing correlated features = (700, 74)\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train_filtered as a NumPy array\n",
    "corr_matrix = np.corrcoef(X_train_filtered, rowvar=False)\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = np.triu(corr_matrix, k=1)\n",
    "\n",
    "# Find indices of features with correlation greater than 0.75 (for higher number of features) or 0.90 (for less number of features) which may be dropped\n",
    "columns_to_drop_indices = np.where(np.abs(upper) > 0.90)\n",
    "#print(columns_to_drop_indices[1])\n",
    "#print(np.unique(columns_to_drop_indices[1]))\n",
    "\n",
    "# Drop the desired features among the ones with high correlation from training dataset\n",
    "X_train_filtered_1 = np.delete(X_train_filtered, np.unique(columns_to_drop_indices[1]), axis=1)\n",
    "\n",
    "print(\"Shape of the training features after removing correlated features =\", X_train_filtered_1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a245eeac-5622-4413-a1ae-93d42f4b5a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the testing features after removing correlated features = (300, 74)\n"
     ]
    }
   ],
   "source": [
    "# Drop the desired features among the ones with high correlation from test set\n",
    "X_test_filtered_1 = np.delete(X_test_filtered, np.unique(columns_to_drop_indices[1]), axis=1)\n",
    "\n",
    "print(\"Shape of the testing features after removing correlated features =\", X_test_filtered_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a203c610-454c-4d2c-a8a7-211eeddc0611",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 74)\n",
      "(300, 74)\n",
      "(700, 5)\n",
      "(300, 5)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train_filtered_1)\n",
    "X_train_scaled = scaler.transform(X_train_filtered_1)\n",
    "X_test_scaled = scaler.transform(X_test_filtered_1)\n",
    "\n",
    "print(np.shape(X_train_scaled))\n",
    "print(np.shape(X_test_scaled))\n",
    "\n",
    "print(np.shape(X_train_clinical))\n",
    "print(np.shape(X_test_clinical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2322d45a-3d93-481d-9bbb-c28721634cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "X_train_clinical_df = pd.DataFrame(X_train_clinical)\n",
    "X_test_clinical_df = pd.DataFrame(X_test_clinical)\n",
    "# Save the clinical data for training and test sets to CSV files\n",
    "X_train_clinical_df.to_csv(os.path.join(main_dir,'data/T-train_data_os_st1_2_clinical_corr_log_harmonized.csv'), index=False, float_format='%.7f')\n",
    "X_test_clinical_df.to_csv(os.path.join(main_dir,'data/T-test_data_os_st1_2_clinical_corr_log_harmonized.csv'), index=False, float_format='%.7f')\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train_scaled)\n",
    "y_train_df = pd.DataFrame({'y_train': y_train})\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test_scaled)\n",
    "y_test_df = pd.DataFrame({'y_test': y_test})\n",
    "\n",
    "# Concatenate the DataFrames horizontally (side by side)\n",
    "combined_df_train = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "combined_df_test = pd.concat([X_test_df, y_test_df], axis=1)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df_train.to_csv(os.path.join(main_dir,'data/T-train_data_os_st1_2_rad_corr_log_harmonized.csv'), index=False, float_format='%.7f')\n",
    "combined_df_test.to_csv(os.path.join(main_dir,'data/T-test_data_os_st1_2_rad_corr_log_harmonized.csv'), index=False, float_format='%.7f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691d3b3-cb99-44c2-9149-f6344119b710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
