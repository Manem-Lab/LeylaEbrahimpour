{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b245837e-cf6a-4b3b-9973-fdea326f1679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neuroCombat as nC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ranksums, ttest_ind, ttest_rel, ks_2samp\n",
    "import os\n",
    "import Nestedcombat as nested\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#import GMMComBat as gmmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "78a012bd-d4fd-4fdc-85c1-839c9fb338ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 1239)\n",
      "(90, 1239)\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "main_dir= \"/home/ulaval.ca/lesee/projects/Project-CNET/\"\n",
    "\n",
    "data = pd.read_excel(os.path.join(main_dir,'data/LORD-CNET-rads-clinical-combat.xlsx'))\n",
    "\n",
    "# Filter the data for stage\n",
    "#filtered_data = data[data['Stage'].isin([1,2])]\n",
    "\n",
    "# Explicitly create a copy of the data\n",
    "filtered_data_copy = data.copy()\n",
    "\n",
    "#drop columns not used in this work\n",
    "filtered_data_copy.drop(columns = ['Center', 'pixel_spacing', 'StudyInstanceUID', 'Recurrence', 'OS_days', 'PFS_days', 'manufacturer'], inplace=True)\n",
    "                        \n",
    "#Remove rows with missing data\n",
    "filtered_data_copy.dropna(inplace=True)\n",
    "print(np.shape(filtered_data_copy))\n",
    "filtered_data_copy.drop(filtered_data_copy[filtered_data_copy['slice_thickness'] == 5].index, inplace=True)\n",
    "print(np.shape(filtered_data_copy))\n",
    "\n",
    "# Store the feature names\n",
    "feature_names = filtered_data_copy.columns.tolist()\n",
    "#print(feature_names)\n",
    "                        \n",
    "#specify the batch list                                            \n",
    "batch_list = ['model', 'kernel', 'slice_thickness']\n",
    "#batch_list = ['manufacturer', 'slice_thickness']\n",
    "\n",
    "#batch_list = ['slice_thickness']\n",
    "\n",
    "# specify the categorical and continous clinical covariates\n",
    "categorical_cols = ['Smoking', 'Subtype', 'Sex']\n",
    "#categorical_cols = ['Sex']\n",
    "continuous_cols = ['Age']\n",
    "patient_name = filtered_data_copy['PatientName']\n",
    "\n",
    "#print(np.shape(patient_name))\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f6349db1-9960-4e88-8cac-2559272a2ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Smoking                              Subtype     Sex  \\\n",
      "1           Smoker  Large cell neuroendocrine carcinoma    Male   \n",
      "2    Former smoker                      Carcinoid tumor  Female   \n",
      "3           Smoker                      Carcinoid tumor  Female   \n",
      "4   Passive smoker                      Carcinoid tumor  Female   \n",
      "5    Former smoker                      Carcinoid tumor    Male   \n",
      "..             ...                                  ...     ...   \n",
      "86   Former smoker                      Carcinoid tumor  Female   \n",
      "87   Former smoker                 Small cell carcinoma  Female   \n",
      "88   Former smoker                      Carcinoid tumor  Female   \n",
      "89      Non smoker                      Carcinoid tumor  Female   \n",
      "90   Former smoker                      Carcinoid tumor  Female   \n",
      "\n",
      "            model kernel  slice_thickness  \n",
      "1      Definition   B40f                1  \n",
      "2      Definition   B40f                1  \n",
      "3      Definition   B40f                1  \n",
      "4      Definition   B40f                1  \n",
      "5      Definition   B40f                2  \n",
      "..            ...    ...              ...  \n",
      "86  SOMATOM Drive  Br43f                2  \n",
      "87  SOMATOM Drive  Br43f                2  \n",
      "88  SOMATOM Drive  Br43f                2  \n",
      "89  SOMATOM Drive  Br43f                2  \n",
      "90  SOMATOM Drive  Br43f                2  \n",
      "\n",
      "[90 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#define a string-based covariate datframe                       \n",
    "covars_string = pd.DataFrame()\n",
    "covars_string[categorical_cols] = filtered_data_copy[categorical_cols].copy()\n",
    "covars_string[batch_list] = filtered_data_copy[batch_list].copy()\n",
    "\n",
    "# Find the counts of each unique value in the batch column\n",
    "#value_counts = covars_string[batch_list].value_counts()\n",
    "\n",
    "# Extract the values that are repeated more than once\n",
    "#repeated_values = value_counts[value_counts > 1].index.tolist()\n",
    "\n",
    "# Display the values that are repeated\n",
    "#print(\"Repeated Values:\")\n",
    "#print(repeated_values)\n",
    "\n",
    "\n",
    "# Define the bins and labels for the categories of batch column\n",
    "#bins = [0, 2, 4, 5]\n",
    "#labels = [1, 2, 3]\n",
    "\n",
    "# Create a new column with categories based on value ranges\n",
    "#covars_string['slice_thickness_new'] = pd.cut(covars_string[batch_list[-1]], bins=bins, labels=labels, include_lowest=True)\n",
    "#batch_list = ['manufacturer', 'slice_thickness_new']\n",
    "#batch_list = ['slice_thickness_new']\n",
    "#covars_string.drop(columns=['slice_thickness'], inplace=True)\n",
    "# Display the DataFrame with the new category column\n",
    "print(covars_string)\n",
    "#print(covars_string['slice_thickness_new'][792]) \n",
    "#print(list(covars_string[\"slice_thickness\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4c239cbf-acc6-47ae-af4a-9bb258ae225a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 4\n",
      "2: 86\n"
     ]
    }
   ],
   "source": [
    "#counts_batch_levels = Counter(list(covars_string[\"slice_thickness\"]))\n",
    "counts_batch_levels = Counter(list(covars_string[\"slice_thickness\"]))\n",
    "\n",
    "for element, count in sorted(counts_batch_levels.items()):\n",
    "    print(f\"{element}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "63a49fcb-4213-49ba-be37-0b8dd3519632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition: 19\n",
      "SOMATOM Definition: 66\n",
      "SOMATOM Drive: 5\n"
     ]
    }
   ],
   "source": [
    "#counts_batch_levels = Counter(list(covars_string[\"slice_thickness\"]))\n",
    "counts_batch_levels = Counter(list(covars_string[\"model\"]))\n",
    "\n",
    "for element, count in sorted(counts_batch_levels.items()):\n",
    "    print(f\"{element}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "46947c0d-b0c2-4429-8a41-193ae56ac4be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B40f: 85\n",
      "Br43f: 5\n"
     ]
    }
   ],
   "source": [
    "#counts_batch_levels = Counter(list(covars_string[\"slice_thickness\"]))\n",
    "counts_batch_levels = Counter(list(covars_string[\"kernel\"]))\n",
    "\n",
    "for element, count in sorted(counts_batch_levels.items()):\n",
    "    print(f\"{element}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "968deaae-095a-4991-8cc1-d3a5402a7fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230, 90)\n",
      "Index(['diagnostics_Image-original_Mean', 'diagnostics_Image-original_Maximum',\n",
      "       'diagnostics_Mask-original_VoxelNum',\n",
      "       'diagnostics_Mask-original_VolumeNum',\n",
      "       'diagnostics_Image-interpolated_Mean',\n",
      "       'diagnostics_Image-interpolated_Minimum',\n",
      "       'diagnostics_Image-interpolated_Maximum',\n",
      "       'diagnostics_Mask-interpolated_VoxelNum',\n",
      "       'diagnostics_Mask-interpolated_VolumeNum',\n",
      "       'diagnostics_Mask-interpolated_Mean',\n",
      "       ...\n",
      "       'gradient_gldm_GrayLevelNonUniformity',\n",
      "       'gradient_gldm_GrayLevelVariance',\n",
      "       'gradient_gldm_HighGrayLevelEmphasis',\n",
      "       'gradient_gldm_LargeDependenceEmphasis',\n",
      "       'gradient_gldm_LargeDependenceHighGrayLevelEmphasis',\n",
      "       'gradient_gldm_LargeDependenceLowGrayLevelEmphasis',\n",
      "       'gradient_gldm_LowGrayLevelEmphasis',\n",
      "       'gradient_gldm_SmallDependenceEmphasis',\n",
      "       'gradient_gldm_SmallDependenceHighGrayLevelEmphasis',\n",
      "       'gradient_gldm_SmallDependenceLowGrayLevelEmphasis'],\n",
      "      dtype='object', length=1230)\n",
      "(90, 6)\n",
      "Index(['Smoking', 'Subtype', 'Sex', 'model', 'kernel', 'slice_thickness'], dtype='object')\n",
      "(90, 1)\n",
      "Index(['Age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print(covars_string.columns.tolist())\n",
    "#load the continous clinical covariate                       \n",
    "covars_quant = filtered_data_copy[continuous_cols]\n",
    "#print(covars_quant.columns.tolist())\n",
    "#specify the features\n",
    "data_df = filtered_data_copy.drop(columns=['PatientName', 'Smoking', 'Age', 'Subtype', 'Sex', 'model', 'kernel', 'slice_thickness'])\n",
    "#print(data_df)\n",
    "\n",
    "#Remove constant radiomic features\n",
    "constant_features = data_df.columns[data_df.nunique() == 1]\n",
    "data_df.drop(constant_features, axis=1, inplace=True)\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "#dat = data_df.T\n",
    "dat = data_df.T.apply(pd.to_numeric)                        \n",
    "#print(dat)\n",
    "#label-encode the string covariates\n",
    "covars_cat = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for col in covars_string:\n",
    "    stringcol = covars_string[col]\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(stringcol))\n",
    "    covars_cat[col] = le.transform(stringcol)\n",
    "#print(np.shape(data_df))\n",
    "print(np.shape(dat))\n",
    "print(data_df.columns)\n",
    "print(np.shape(covars_cat))\n",
    "print(covars_cat.columns)\n",
    "print(np.shape(covars_quant))\n",
    "print(covars_quant.columns)\n",
    "#print(len(covars_cat[batch_list[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7732bc6b-7085-497b-8965-4adf2766f516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Smoking', 'Subtype', 'Sex']\n",
      "['Age']\n",
      "    Smoking  Subtype  Sex  model  kernel  slice_thickness  Age\n",
      "0         3        1    1      0       0                0   68\n",
      "1         0        0    0      0       0                0   61\n",
      "2         3        0    0      0       0                0   62\n",
      "3         2        0    0      0       0                0   74\n",
      "4         0        0    1      0       0                1   70\n",
      "..      ...      ...  ...    ...     ...              ...  ...\n",
      "85        0        0    0      2       1                1   67\n",
      "86        0        2    0      2       1                1   66\n",
      "87        0        0    0      2       1                1   74\n",
      "88        1        0    0      2       1                1   70\n",
      "89        0        0    0      2       1                1   56\n",
      "\n",
      "[90 rows x 7 columns]\n",
      "Number of NaN values in covars: 0\n"
     ]
    }
   ],
   "source": [
    "covars_cat_reset = covars_cat.reset_index(drop=True)\n",
    "covars_quant_reset = covars_quant.reset_index(drop=True)\n",
    "\n",
    "#concatenate the label-enoded categorical (batch+clinical) and continous clinical covariates                         \n",
    "covars = pd.concat([covars_cat_reset, covars_quant_reset], axis=1)\n",
    "print(categorical_cols)\n",
    "print(continuous_cols)\n",
    "print(covars)\n",
    "#covars = covars_cat_reset\n",
    "#print(covars)\n",
    "#print(type(covars['Age'][0]))\n",
    "#print(type(dat))\n",
    "#print(dat)\n",
    "\n",
    "# Check if there are any NaN values in covars and batch_col\n",
    "covars_nan_count = np.sum(np.sum(np.isnan(data_df)))\n",
    "#batch_col_nan_count = np.sum(np.isnan(batch_col))\n",
    "\n",
    "print(\"Number of NaN values in covars:\", covars_nan_count)\n",
    "#print(\"Number of NaN values in batch_col:\", batch_col_nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "157a9457-bbc0-4901-a2a6-ecf69fe14358",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model', 'kernel', 'slice_thickness']\n",
      "['Smoking' 'Subtype' 'Sex' 'model' 'kernel' 'slice_thickness' 'Age']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37259/456946222.py:5: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  batch_col = np.where(covar_labels==batch_list)[0][0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[193], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m covar_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(covars\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(covar_labels)\n\u001b[0;32m----> 5\u001b[0m batch_col \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcovar_labels\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mbatch_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_col)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#covars = np.array(covars, dtype='object') \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#print(covars.values[:,batch_col])\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "print(batch_list)\n",
    "#covars = covars_cat_reset\n",
    "covar_labels = np.array(covars.columns)\n",
    "print(covar_labels)\n",
    "batch_col = np.where(covar_labels==batch_list)[0][0]\n",
    "print(batch_col)\n",
    "#covars = np.array(covars, dtype='object') \n",
    "#print(covars.values[:,batch_col])\n",
    "\n",
    "(batch_levels, sample_per_batch) = np.unique(covars[:,batch_col],return_counts=True)\n",
    "print(batch_levels)\n",
    "print(sample_per_batch)\n",
    "#print([list(np.where(covars[:,batch_col]==2)[0])])\n",
    "#print(covars[:,batch_col][792])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "913d9cbb-705f-4b5e-8dec-339f9dc477d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230, 90)\n",
      "ROUND 1:\n",
      "Harmonizing by model...\n",
      "ComBat with Raw Data...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "Harmonizing by kernel...\n",
      "ComBat with Raw Data...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "Harmonizing by slice_thickness...\n",
      "ComBat with Raw Data...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "ROUND 2:\n",
      "Harmonizing by model...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "Harmonizing by slice_thickness...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "ROUND 3:\n",
      "Harmonizing by model...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n"
     ]
    }
   ],
   "source": [
    "#covars = covars_cat_reset\n",
    "#output_data = nested.NestedComBat(dat, covars, batch_list, categorical_cols=categorical_cols,\n",
    "#                                   continuous_cols=continuous_cols, drop=True, write_p=True, filepath=main_dir)\n",
    "print(np.shape(dat))\n",
    "#print(covars)\n",
    "#print(batch_list[0])\n",
    "#print(categorical_cols)\n",
    "#print(continuous_cols)\n",
    "\n",
    "# Fit the scaler on your data and transform it\n",
    "#scaled_data = scaler.fit_transform(dat)\n",
    "#print(np.shape(dat))\n",
    "\n",
    "#dat_first_5_rows = (dat.head(5)).values\n",
    "#print(dat_first_5_rows)\n",
    "\n",
    "output_data = nested.NestedComBat(dat, covars, batch_list, categorical_cols=categorical_cols,\n",
    "                                   continuous_cols=continuous_cols, drop=False, write_p=False, filepath=main_dir)\n",
    "output_data_reset = output_data.reset_index(drop=True)\n",
    "patient_name_reset = patient_name.reset_index(drop=True)\n",
    "write_df = pd.concat([patient_name_reset, output_data_reset], axis=1)\n",
    "write_df.to_csv(os.path.join(main_dir,'data_combat/combat_harmonized_features_nested_not_dropped.csv'), float_format='%.7f', index= False)\n",
    "\n",
    "\n",
    "\n",
    "#data_combat = nC.neuroCombat(dat= dat.values,\n",
    "#                          covars=covars,\n",
    "#                          batch_col=batch_list[0]\n",
    "#                          ,categorical_cols=categorical_cols,\n",
    "#                          continuous_cols=continuous_cols\n",
    "#                            )[\"data\"]\n",
    "#pd.DataFrame(data_combat).to_csv(os.path.join(main_dir,'data_combat/combat_harmonized_features_slice_new.csv'), float_format='%.7f', index= False)\n",
    "\n",
    "\n",
    "#print(estimates_combat.keys())\n",
    "#print(estimates_combat['gamma.star'])\n",
    "#print(estimates_combat['delta.star'])\n",
    "#print(estimates_combat['mod.mean'])\n",
    "\n",
    "#dict_keys(['gamma_hat', 'delta_hat', 'gamma_bar', 't2', 'a_prior', 'b_prior', 'batches', 'var.pooled', 'stand.mean', 'mod.mean', 'gamma.star', 'delta.star'])\n",
    "\n",
    "\n",
    "#output_data = gmmc.GMMComB['gamma']at(dat, caseno, covars,  filepath=filepath2, categorical_cols=categorical_cols,\n",
    "#                             continuous_cols=continuous_cols, write_p=True, plotting=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cf0ab17-bda0-4559-bcf7-926e549f19d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998, 5)\n",
      "(1231, 998)\n",
      "(3,)\n",
      "(1,)\n",
      "ROUND 1:\n",
      "Harmonizing by slice_thickness...\n",
      "ComBat with Raw Data...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ulaval.ca/lesee/.local/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3747: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ulaval.ca/lesee/.local/lib/python3.11/site-packages/numpy/core/_methods.py:258: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998, 1231)\n"
     ]
    }
   ],
   "source": [
    "# output_df = pd.DataFrame.from_records(output_data.T)\n",
    "# output_df.columns = feature_cols\n",
    "\n",
    "output_data_reset = output_data.reset_index(drop=True)\n",
    "patient_name_reset = patient_name.reset_index(drop=True)\n",
    "write_df = pd.concat([patient_name_reset, output_data_reset], axis=1)\n",
    "write_df.to_csv(os.path.join(main_dir,'data_combat/combat_harmonized_features.csv'), float_format='%.7f', index= False)\n",
    "                        \n",
    "#nested.feature_kstest_histograms(output_data, covars, batch_list, main_dir)\n",
    "\n",
    "#f_dict = nested.MultiComBat(output_data.T, covars, batch_list, filepath=main_dir, categorical_cols=categorical_cols,\n",
    "#                          continuous_cols=continuous_cols, write_p=True, plotting=True)\n",
    "#for col in batch_list:\n",
    "#    write_df = pd.concat([patient_name, f_dict[col]])\n",
    "#    write_df.to_csv(os.path.join(main_dir, 'data_combat/combat_'+col+'_harmonized_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f6d5d-6043-4557-a395-e8bb129b9362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
