{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "badbf7db-a00b-4b4f-abbc-96016a6a544b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, KFold, RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, f_regression\n",
    "from skrebate import ReliefF, SURF, MultiSURF\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (DotProduct, WhiteKernel, RBF, Matern, ConstantKernel, ExpSineSquared, RationalQuadratic, Product)\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from scipy.stats import pearsonr\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "#from skopt import BayesSearchCVba\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "241bdd15-96d5-4dbd-8827-33e7c2e76f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features =  (1000, 1235)\n"
     ]
    }
   ],
   "source": [
    "# get the start time\n",
    "st = time.time()\n",
    "file_name = 'T-OS_st1-2_dataset-corr'\n",
    "#Load the data\n",
    "main_dir= \"/home/ulaval.ca/lesee/projects/Project2-synergiqc/OS/\"\n",
    "\n",
    "data = pd.read_excel(os.path.join(main_dir,'data/T-SynergiQc_annotated-clinical-radiomics1713-normal.xlsx'))\n",
    "# Identify and drop columns with all NaN values\n",
    "#data.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Filter the data for stage\n",
    "filtered_data = data[data['Stage'].isin([1,2])]\n",
    "\n",
    "# Explicitly create a copy of the data\n",
    "filtered_data_copy = filtered_data.copy()\n",
    "\n",
    "filtered_data_copy.drop(columns=['PatientName', 'PatientID', 'StudyInstanceUID', 'Stage',  'Recurrence', 'PFS-months', 'PFS-days'], inplace=True)\n",
    "\n",
    "#Remove rows with missing data\n",
    "filtered_data_copy.dropna(inplace=True)\n",
    "                                            \n",
    "features = filtered_data_copy.drop(columns=['OS-months', 'OS-days'])\n",
    "print(\"number of features = \", np.shape(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3cbd06d2-9d7b-4810-aa43-782eed092b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the target variable for stage 1 and stage 2\n",
    "target = filtered_data_copy['OS-months']\n",
    "#event = filtered_data_copy['VitalStatus']\n",
    "#print(\"number of features = \", np.shape(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a32dd414-cd5c-4a19-9601-d10f421c1949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove constant radiomic features\n",
    "#constant_features = features.columns[features.nunique() == 1]\n",
    "#features.drop(constant_features, axis=1, inplace=True)\n",
    "features = features.loc[:, features.var() != 0.0]\n",
    "#print(\"number of non-constant features = \", np.shape(features))\n",
    "# Store the feature names\n",
    "feature_names = features.columns.tolist()\n",
    "#print(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da098e6e-a45f-402f-b077-4e42c8cb47e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training features after removing constant features = (700, 1231)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "# Define the list of columns to drop\n",
    "columns_clinical_to_drop = ['Smoking', 'Age', 'Subtype', 'Sex']\n",
    "# Drop the clinical data from X_train_scaled and X_test_scaled\n",
    "X_train_filtered = X_train.drop(columns=columns_clinical_to_drop)\n",
    "X_test_filtered = X_test.drop(columns=columns_clinical_to_drop)\n",
    "\n",
    "#Feature selection based on training set\n",
    "#remove all features that are constant \n",
    "#X_train_filtered = X_train_filtered.loc[:, X_train_filtered.var() != 0.0]\n",
    "\n",
    "print(\"Shape of the training features after removing constant features =\", np.shape(X_train_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eecf01de-de3b-4d13-b518-efc472389c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training features after removing correlated features = (700, 197)\n"
     ]
    }
   ],
   "source": [
    "#get correlations of each features in dataset and remove one of each highly correlated to each other \n",
    "corr_matrix = X_train_filtered.corr()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find name of feature columns with correlation greater than 0.9 which may be dropped\n",
    "column_to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "\n",
    "#drop the desired fetures among the ones with high correlation \n",
    "X_train_filtered.drop(labels = column_to_drop, axis=1, inplace=True)\n",
    "print(\"Shape of the training features after removing correlated features =\", np.shape(X_train_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a245eeac-5622-4413-a1ae-93d42f4b5a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the test features after dropping high correlated features = (300, 197)\n"
     ]
    }
   ],
   "source": [
    "X_test_filtered = X_test_filtered[X_train_filtered.columns]\n",
    "#print(X_test_filtered)\n",
    "\n",
    "print(\"Shape of the test features after dropping high correlated features =\", np.shape(X_test_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a203c610-454c-4d2c-a8a7-211eeddc0611",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 197)\n",
      "(300, 197)\n",
      "(700, 4)\n",
      "(300, 4)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train_filtered)\n",
    "X_train_scaled = scaler.transform(X_train_filtered)\n",
    "X_test_scaled = scaler.transform(X_test_filtered)\n",
    "\n",
    "print(np.shape(X_train_scaled))\n",
    "print(np.shape(X_test_scaled))\n",
    "\n",
    "# Extract the columns to be dropped from X_train_scaled and X_test_scaled\n",
    "X_train_clinical = X_train[columns_clinical_to_drop]\n",
    "X_test_clinical = X_test[columns_clinical_to_drop]\n",
    "\n",
    "\n",
    "#scaler = preprocessing.StandardScaler().fit(X_train_clinical)\n",
    "#X_train_clinical_scaled = scaler.transform(X_train_clinical)\n",
    "#X_test_clinical_scaled = scaler.transform(X_test_clinical)\n",
    "print(np.shape(X_train_clinical))\n",
    "print(np.shape(X_test_clinical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2322d45a-3d93-481d-9bbb-c28721634cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "X_train_clinical_df = pd.DataFrame(X_train_clinical)\n",
    "X_test_clinical_df = pd.DataFrame(X_test_clinical)\n",
    "# Save the clinical data for training and test sets to CSV files\n",
    "X_train_clinical_df.to_csv(os.path.join(main_dir,'data/T-train_data_os_st1_2_clinical_corr_harmonized.csv'), index=False, float_format='%.7f')\n",
    "X_test_clinical_df.to_csv(os.path.join(main_dir,'data/T-test_data_os_st1_2_clinical_corr_harmonized.csv'), index=False, float_format='%.7f')\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train_scaled)\n",
    "y_train_df = pd.DataFrame({'y_test': y_train})\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test_scaled)\n",
    "y_test_df = pd.DataFrame({'y_test': y_test})\n",
    "\n",
    "# Concatenate the DataFrames horizontally (side by side)\n",
    "combined_df_train = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "combined_df_test = pd.concat([X_test_df, y_test_df], axis=1)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df_train.to_csv(os.path.join(main_dir,'data/T-train_data_os_st1_2_rad_corr_harmonized.csv'), index=False, float_format='%.7f')\n",
    "combined_df_test.to_csv(os.path.join(main_dir,'data/T-test_data_os_st1_2_rad_corr_harmonized.csv'), index=False, float_format='%.7f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691d3b3-cb99-44c2-9149-f6344119b710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
